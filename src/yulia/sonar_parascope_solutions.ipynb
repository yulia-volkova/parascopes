{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1cacb7-638e-400b-9759-67c5e476d7c4",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " # Section 3: SONAR Parascopes - Trained Probes\n",
    " ============================================\n",
    "\n",
    " While continuation parascopes directly use the model's own generation capabilities,\n",
    " SONAR parascopes take a different approach by learning to map residual streams to\n",
    " text embeddings that can be decoded back to text.\n",
    "\n",
    "![AutoEncoder Map ParaScope](https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/07873b3421363d38f1cee7649b8bd73fccd43300afd5c2fa.png)\n",
    "\n",
    " The SONAR approach:\n",
    " 1. Train a probe (Linear or MLP) to map from residual stream â†’ SONAR embedding space\n",
    " 2. Use SONAR's decoder to convert embeddings back to text\n",
    " 3. This allows us to extract semantic content without relying on the model's generation\n",
    "\n",
    " Learning objectives:\n",
    " 1. Understand the SONAR text autoencoder and its embedding space\n",
    " 2. Load pre-generated datasets of residual streams and SONAR embeddings\n",
    " 3. Train probes to map between these spaces\n",
    " 4. Evaluate and compare with continuation parascopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada4555-b87b-4619-b6e2-79bed3811f98",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Setup and Installation\n",
    "\n",
    " First, install SONAR and other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdbee84-4905-4256-ba71-1c055d55d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "#!pip install -q sonar-space torch torchvision transformer-lens sentence-transformers\n",
    "#\n",
    "#!pip install -q matplotlib seaborn pandas numpy scikit-learn einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43116cb-1deb-458c-9c17-f630a40ec746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import einops\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import load_dataset\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# For the model\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# SONAR imports\n",
    "from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
    "from sonar.inference_pipelines.text import EmbeddingToTextModelPipeline\n",
    "\n",
    "# For evaluation\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Disable gradients by default\n",
    "torch.set_grad_enabled(False)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.bfloat16\n",
    "print(f\"Using device: {DEVICE}, dtype: {DTYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bcef3-d30d-489d-9504-04328228a57b",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0ea75-a61b-43c8-a695-675828cf62b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933f7f159add4fbab7323f55d2bca8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-3B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55d615-0f55-49ba-9cf8-6bee899170fc",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Exercise 1: Generating Training Data\n",
    "\n",
    " Since we want the probe to match \"what the model might output\", we need data of what the model's output might look like.\n",
    " Two-step process: (1) load dataset + generate prompts, (2) use prompts to generate model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa0cd16-b464-4b8b-b932-f2cd31df6804",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### Part 1: Generating Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e5265-b6e6-43a8-88d7-0dfd7d2969fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ce311e80384e3cab8c1218b7d33e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35f0a76b53e4d1c8664f063378984bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef2b6d73d1b49b28917fa3b7aa2ee49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8637c9141b49db860d34d046293797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63217ab81374ef69342539d9a707e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 training examples\n",
      "Example prompts:\n",
      "0: ['Write a biographical article on a prominent female figure from the 18th or 19th century, exploring the intersection of individual freedom and societal expectations in her life and works. The article should delve into the ways in which this figure challenged and subverted traditional norms, as well as the lasting impact of her writing on the cultural and social landscape.']\n",
      "1: ['Write a feature article on the resurgence of the importance of play, which includes discussions of the biological and spiritual underpinnings of play, the impact of play deprivation on childhood development, and the tension between the nostalgic value of childhood play and the pressures of modern parental expectations, and the piece should be approximately 6-8 paragraphs long.']\n",
      "2: ['Write a comprehensive article on HIV transmission, which includes the modes of transmission, risk factors, and prevention methods, and the piece should be approximately 3-5 paragraphs long.']\n",
      "3: ['Write a comprehensive guide to software licenses, which includes the differences between free, proprietary, and open-source software, the concept of copyleft, and the distinctions between shareware and freeware, and should be approximately 10 paragraphs long.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "def format_prompt(prompt: list[str] | str, system_prompt: str = None) -> list[str]:\n",
    "    def format_prompt_string(prompt: str) -> str:\n",
    "        \"\"\"Format prompt using the model's chat template.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        if system_prompt:\n",
    "            messages.insert(0, {\"role\": \"system\", \"content\": system_prompt})\n",
    "        return model.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    if isinstance(prompt, str):\n",
    "        return [format_prompt_string(prompt)]\n",
    "    elif isinstance(prompt, list):\n",
    "        return [format_prompt_string(p) for p in prompt]\n",
    "\n",
    "def format_question_string(text: str, max_chars: int = 32000) -> str:\n",
    "    \"\"\"Transform existing text into a generation prompt.\"\"\"\n",
    "    return f\"\"\"Content: {text[:max_chars]}\n",
    "\n",
    "REQUEST: Write a prompt based on the above text, that is a single-paragraph, high-level description. Make the prompt in the format: \"Write a (article/piece/entry), which includes (2-5 topics). The piece should be approximately (many n-paragraphs) long.\"\n",
    "\n",
    "Only provide the prompt, do not write anything else.\"\"\"\n",
    "\n",
    "def format_question(text: list[str] | str, max_chars: int = 4000) -> list[str]:\n",
    "    if isinstance(text, str):\n",
    "        return [format_question_string(text, max_chars)]\n",
    "    elif isinstance(text, list):\n",
    "        return [format_question_string(t, max_chars) for t in text]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid text type: {type(text)}\")\n",
    "\n",
    "# Load dataset and generate training data\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\", streaming=True)\n",
    "train_dataloader = DataLoader(dataset.take(4), batch_size=1)\n",
    "# Note: for whatever reason with TransformerLens HookedTransformer,\n",
    "# the generation does not work correctly with batching?\n",
    "# TODO: make it work with batch > 1\n",
    "\n",
    "# Step 1: Generate prompts from texts\n",
    "prompts = []\n",
    "for data in train_dataloader:  # Start with just 4 examples\n",
    "    # Format the meta-prompt properly\n",
    "    meta_prompt = format_question(data[\"text\"])\n",
    "    formatted_prompt = format_prompt(meta_prompt, system_prompt=\"You are a prompt-writing assistant. You are given a text and you need to write a prompt that will generate a response that is similar to the text.\")\n",
    "\n",
    "    # Tokenize and generate\n",
    "    model.tokenizer.pad_token_id = model.tokenizer.eos_token_id\n",
    "    prompt_tokens = model.to_tokens(\n",
    "        formatted_prompt, prepend_bos=False, padding_side=\"left\")\n",
    "    generated_tokens = model.generate(\n",
    "        prompt_tokens,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    # Extract just the generated part\n",
    "    output_tokens = generated_tokens[:, len(prompt_tokens[0]):-1]\n",
    "    generated_prompt = model.to_string(output_tokens)\n",
    "\n",
    "    prompts.extend([t.strip() for t in generated_prompt])\n",
    "\n",
    "print(f\"Generated {len(prompts)} training examples\")\n",
    "print(f\"Example prompts:\")\n",
    "[print(f\"{i}: {[p]}\") for i, p in enumerate(prompts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f75b6-9f0c-4e0c-8695-ac3838619092",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### Part 2: Generate Model Outputs from Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ece2b-288f-4854-8687-a8ca1709afa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating output 1/4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f097246fb77a433d91ad750c70422575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating output 2/4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8123e0b21254fcda87f94ab6c142440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating output 3/4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de144b2495b4ad8a0081a01706d9be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating output 4/4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b46d4ec02cf47ef874d1da9d212a7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 model outputs\n",
      "Example outputs:\n",
      "0: ['**Mary Wollstonecraft: A Pioneer for Feminist Rights and Individual Freedom**\\n\\nMary Wollstonecraft (1759-1797) was a trailblazing English writer, philosopher, and advocate for women\\'s rights, whose life and works continue to inspire and challenge societal expectations to this day. As a prominent figure in the Enlightenment era, Wollstonecraft navigated the complexities of individual freedom and societal norms, leaving an indelible mark on the cultural and social landscape.\\n\\n**Early Life and Education**\\n\\nBorn in London, Wollstonecraft was the eldest of seven children to a family of modest means. Her father, Robert Wollstonecraft, was a lawyer who died when Mary was just nine years old. Her mother, Elizabeth Stansfield, was a widow who struggled to provide for her children. Despite these challenges, Wollstonecraft\\'s love for learning and reading was fostered from an early age. She was largely self-educated, devouring books on philosophy, literature, and politics.\\n\\n**The Vindication of Rights of Woman**\\n\\nIn 1792, Wollstonecraft published her magnum opus, \"A Vindication of the Rights of Woman,\" a scathing critique of the patriarchal society that constrained women\\'s potential. In this influential work, Wollstonecraft argued that women were not inherently inferior to men and that their education and economic independence were essential for their personal and social development. She challenged traditional notions of femininity, emphasizing']\n",
      "1: ['The Resurgence of Play: Unlocking the Secrets of a Lost Art\\n\\nIn an era dominated by screens and structured activities, the importance of play has been relegated to the background. However, in recent years, there has been a growing recognition of the vital role that play has played in human development, from ancient civilizations to modern times. As we navigate the complexities of childhood development, the biological and spiritual underpinnings of play are coming to the forefront, revealing a more nuanced understanding of this often-maligned activity.\\n\\nFrom a biological perspective, play has long been recognized as an essential component of childhood growth and development. Studies have shown that play stimulates the release of endorphins, dopamine, and other neurotransmitters that promote learning, creativity, and socialization (Hill, 2004). Play also allows children to experiment, explore, and take risks, which are critical skills for developing problem-solving abilities and navigating uncertainty. Moreover, play has been linked to improved cognitive functioning, including memory, attention, and language skills (Hirsh-Pasek et al., 2015).\\n\\nFrom a spiritual perspective, play has been revered across cultures and throughout history. In many indigenous cultures, play is seen as a way of connecting with nature, the divine, and the community. In ancient Greece, play was considered an essential part of human flourishing, with philosophers like Aristotle arguing that play was a key component of human happiness and fulfillment (Aristotle, 1998). In modern times,']\n",
      "2: [\"**Understanding HIV Transmission: Modes, Risk Factors, and Prevention Methods**\\n\\nHuman Immunodeficiency Virus (HIV) is a global health crisis that affects millions of people worldwide. HIV transmission occurs when the virus is passed from one person to another through various routes, and it is essential to understand these modes of transmission, risk factors, and prevention methods to prevent the spread of the virus. **Modes of Transmission:** HIV can be transmitted through bodily fluids, such as blood, semen, vaginal and rectal fluids, and breast milk. Unprotected sex with an infected person is the most common mode of transmission, accounting for approximately 85% of new infections. Other modes of transmission include sharing needles or syringes, mother-to-child transmission during pregnancy, childbirth, or breastfeeding, and blood transfusions from an infected donor.\\n\\n**Risk Factors:** Certain factors increase an individual's risk of contracting HIV. These include having multiple sex partners, engaging in unprotected sex, not using condoms, and having a history of sex work or injecting drug use. Injecting drug users who share needles or equipment are also at higher risk of transmission. Additionally, individuals with weakened immune systems, such as those with HIV/AIDS or undergoing chemotherapy, are more susceptible to HIV infection. **Prevention Methods:** Fortunately, there are several effective ways to prevent HIV transmission. The most effective method is consistent and correct use of condoms during sex, which can reduce the risk of transmission by up to 82%. Pre-exposure prophylaxis (\"]\n",
      "3: [\"**A Comprehensive Guide to Software Licenses**\\n\\nThe world of software licenses can be complex and overwhelming, especially for individuals and businesses looking to leverage software solutions. In this guide, we will explore the differences between free, proprietary, and open-source software, the concept of copyleft, and the distinctions between shareware and freeware.\\n\\n**Free Software**\\n\\nFree software, also known as open-source software, is software that is freely available for anyone to use, modify, and distribute. The source code is typically made available, allowing users to review, modify, and contribute to the codebase. Free software is often developed collaboratively by a community of developers, which can lead to rapid innovation and improvement. Examples of free software include the Linux operating system, Mozilla Firefox, and LibreOffice.\\n\\n**Proprietary Software**\\n\\nProprietary software, on the other hand, is software that is owned and controlled by a single entity, such as a company or individual. The source code is typically not made available, and users are not allowed to modify or distribute the software without permission. Proprietary software is often developed by a single company or individual, and the software's intellectual property rights are closely guarded. Examples of proprietary software include Microsoft Office, Adobe Photoshop, and Skype.\\n\\n**Open-Source Software**\\n\\nOpen-source software is a subset of free software that is specifically designed to be highly customizable and modifiable. Open-source software is typically released under a permissive license, which allows users to modify and distribute\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "model_outputs = []\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"Generating output {i+1}/{len(prompts)}...\")\n",
    "\n",
    "    # Format and tokenize the prompt\n",
    "    formatted_prompt = format_prompt(prompt)\n",
    "    prompt_tokens = model.to_tokens(\n",
    "        formatted_prompt, prepend_bos=False, padding_side=\"left\")\n",
    "\n",
    "    # Generate response\n",
    "    output_tokens = model.generate(\n",
    "        prompt_tokens,\n",
    "        max_new_tokens=300,\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Extract just the generated part\n",
    "    generated_tokens = output_tokens[:, len(prompt_tokens[0]):]\n",
    "    generated_text = model.to_string(generated_tokens)[0]\n",
    "\n",
    "    model_outputs.append(generated_text.strip())\n",
    "\n",
    "print(f\"Generated {len(model_outputs)} model outputs\")\n",
    "print(f\"Example outputs:\")\n",
    "[print(f\"{i}: {[o]}\") for i, o in enumerate(model_outputs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf50e6-ae94-4c5c-b3f2-4f35d78c7384",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### Part 3: Loading Pre-made Data\n",
    " The above takes too long to run, so we'll load pre-made data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2527776-bcf8-4a0a-ac77-ba239f6e0033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: [0]\n",
      "prompt: ['Write a Chapter titled \"The Quiet Revolution of Jane Austen\\'s Independence\", exploring the theme of Austen\\'s advocacy for female independence and the principles of freedom and self-regulation in her novels, contrasting her quiet yet powerful impact with the more explosive consequences of American and French Revolutions of her time.']\n",
      "completion: [\"**Chapter 7: The Quiet Revolution of Jane Austen's Independence**\\n\\nIn an era where the French Revolution's loud declarations of liberty, equality, and fraternity had sparked fervent discussions and bloody conflicts across Europe, a quieter revolution was unfolding in the English countryside. Jane Austen, a writer often overlooked for her time, was quietly advocating for female independence and the principles of freedom and self-regulation in her novels. While the likes of Maximilien Robespierre and George Washington were railing against tyranny and demanding radical change, Austen was working to empower women through subtle yet profound literary endorsements.\\n\\nAusten's writing career spanned the late 18th and early 19th centuries, a period marked by significant social and economic changes. The Industrial Revolution had created new opportunities for women to enter the workforce, but the constraints of a patriarchal society ensured that their choices and ambitions were often limited. Austen's novels, particularly those featuring strong female protagonists like Elizabeth Bennet in _Pride and Prejudice_ and Elinor Dashwood in _Sense and Sensibility_, proposed a radical alternative to the traditional notion of femininity.\\n\\nIn _Pride and Prejudice_, Austen subverts the conventional notion of a woman's role in society by depicting a heroine who is intelligent, witty, and determined to marry for love rather than convenience. Elizabeth Bennet's opposition to Mr. Collins's proposal, with its implication of a mercenary marriage, is a pointed critique of the social pressures that forced women into unwanted alliances. Austen shows that a woman's happiness and fulfillment depend on her own agency and self-respect, not on the favor of a man.\\n\\nSimilarly, in _Sense and Sensibility_, Austen explores the theme of female independence through the characters of Elinor and Marianne Dashwood. Elinor's cautious and practical approach to love and relationships serves as a foil to Marianne's emotional and expressive nature. While Marianne's enthusiasm and passion are eventually tempered by the demands of reality, Elinor's steady determination to make her own way in life remains a powerful symbol of female autonomy.\\n\\nAusten's advocacy for female independence was not limited to her novels. In her letters and personal life, she demonstrated a commitment to the values of self-regulation and personal responsibility. A woman of modest means and limited social connections, Austen was aware of the restrictions placed on her by her sex and her station. Yet, she refused to be constrained by these limitations, instead cultivating a spirit of independence and self-reliance that informed her writing and shaped her relationships.\\n\\nIn contrast to the more explosive consequences of the American and French Revolutions, which aimed to overthrow entire systems of power and social order, Austen's quiet revolution was more subtle and insidious. Her novels and letters, written in a tone of gentle persuasion rather than revolutionary fervor, seeped into the social consciousness like a gentle stream, influencing generations of women to come. By depicting strong, independent female characters and advocating for the value of personal autonomy, Austen contributed to a gradual shift in societal attitudes, one that recognized the agency and dignity of women.\\n\\nAusten's legacy is a testament to the power of quiet, incremental change. Her novels, written during a time of great social upheaval, offer a vision of a more just and equitable society, one in which women are valued for their own worth and agency rather than being defined by their relationships with men. As we reflect on the quiet revolution of Jane Austen's independence, we are reminded that true change often begins with small, subtle shifts in our understanding of the world and our place within it.\\n\\nIn the end, Austen's legacy serves as a reminder that revolution is not always loud or dramatic. Sometimes, the most profound transformations occur through quiet, steady efforts, as individuals and societies work together to create a more just and equitable world. As we celebrate the quiet revolution of Jane Austen's independence, we honor a woman who, through her writing and her life, has inspired generations to stand up for their own freedom and dignity.\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"nickypro/fineweb-llama3b-regen\", split=\"train\")\n",
    "\n",
    "[print(f\"{k}: {[v]}\") for k,v in dataset[0].items()]\n",
    "# {id: 0, prompt: \"...\", completion: \"...\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a912b-1da8-49bb-a908-54ee1d2532ba",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### Part 4: Splitting into Sections\n",
    " As we want to predict that the \"next section\" of the text will say, we need to split the text into sections.\n",
    " I choose to split the text by paragraphs, but it is also reasonable to split it by sentences or something similar.\n",
    " For the data here, we want data of the form:\n",
    " [prompt, section_1, section_2, section_3, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987cffe-6f6a-4e7f-a01b-37d0ed37fda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/1000000 [00:00<02:54, 5730.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 25 Jul 2025\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWrite a Chapter titled \"The Quiet Revolution of Jane Austen\\'s Independence\", exploring the theme of Austen\\'s advocacy for female independence and the principles of freedom and self-regulation in her novels, contrasting her quiet yet powerful impact with the more explosive consequences of American and French Revolutions of her time.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], \"**Chapter 7: The Quiet Revolution of Jane Austen's Independence**\\n\\n\", \"In an era where the French Revolution's loud declarations of liberty, equality, and fraternity had sparked fervent discussions and bloody conflicts across Europe, a quieter revolution was unfolding in the English countryside. Jane Austen, a writer often overlooked for her time, was quietly advocating for female independence and the principles of freedom and self-regulation in her novels. While the likes of Maximilien Robespierre and George Washington were railing against tyranny and demanding radical change, Austen was working to empower women through subtle yet profound literary endorsements.\\n\\n\", \"Austen's writing career spanned the late 18th and early 19th centuries, a period marked by significant social and economic changes. The Industrial Revolution had created new opportunities for women to enter the workforce, but the constraints of a patriarchal society ensured that their choices and ambitions were often limited. Austen's novels, particularly those featuring strong female protagonists like Elizabeth Bennet in _Pride and Prejudice_ and Elinor Dashwood in _Sense and Sensibility_, proposed a radical alternative to the traditional notion of femininity.\\n\\n\", \"In _Pride and Prejudice_, Austen subverts the conventional notion of a woman's role in society by depicting a heroine who is intelligent, witty, and determined to marry for love rather than convenience. Elizabeth Bennet's opposition to Mr. Collins's proposal, with its implication of a mercenary marriage, is a pointed critique of the social pressures that forced women into unwanted alliances. Austen shows that a woman's happiness and fulfillment depend on her own agency and self-respect, not on the favor of a man.\\n\\n\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def split_text_into_paragraphs(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a block of text into paragraphs.\n",
    "    Paragraphs are separated by two or more newlines.\n",
    "    The convention we choose is to have the newlines stored at the end of each paragraph.\n",
    "    The list should combine to give the original text.\n",
    "    \"\"\"\n",
    "    paragraphs = [p+\"\\n\\n\" for p in text.split('\\n\\n')]\n",
    "    return paragraphs\n",
    "\n",
    "def split_dataset_prompt_and_sections(dataset) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    For each example in the dataset, keeps the prompt as a single string,\n",
    "    and splits the 'completion' field into paragraphs.\n",
    "    Returns a list of lists:\n",
    "    [ [prompt, section_1, section_2, ...], ... ]\n",
    "    \"\"\"\n",
    "    split_data = []\n",
    "    for i, example in enumerate(tqdm(dataset)):\n",
    "        prompt = format_prompt(example[\"prompt\"])\n",
    "        completion = example[\"completion\"]\n",
    "        completion_paragraphs = split_text_into_paragraphs(completion)\n",
    "        # The first element is the prompt (as a single string), then the completion paragraphs\n",
    "        split_text = [prompt] + completion_paragraphs\n",
    "        split_data.append({\"id\": i, \"split_text\": split_text})\n",
    "\n",
    "        if i > 100:\n",
    "            # Lazy mode: only do 100 examples\n",
    "            break\n",
    "    return split_data\n",
    "\n",
    "# Example usage:\n",
    "split_sections = split_dataset_prompt_and_sections(dataset)\n",
    "print(split_sections[0][\"split_text\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff91af9-a7c2-4e8a-948c-d8cdcecf426a",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Alternatively, I don't like waiting for this either, so we can just load the pre-split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a1387-f02c-475c-b3fa-787fa3ba56ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'split_text': ['<|start_header_id|>user<|end_header_id|>\\nWrite a Chapter titled \"The Quiet Revolution of Jane Austen\\'s Independence\", exploring the theme of Austen\\'s advocacy for female independence and the principles of freedom and self-regulation in her novels, contrasting her quiet yet powerful impact with the more explosive consequences of American and French Revolutions of her time.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n', \"**Chapter 7: The Quiet Revolution of Jane Austen's Independence**\\n\\n\", \"In an era where the French Revolution's loud declarations of liberty, equality, and fraternity had sparked fervent discussions and bloody conflicts across Europe, a quieter revolution was unfolding in the English countryside. Jane Austen, a writer often overlooked for her time, was quietly advocating for female independence and the principles of freedom and self-regulation in her novels. While the likes of Maximilien Robespierre and George Washington were railing against tyranny and demanding radical change, Austen was working to empower women through subtle yet profound literary endorsements.\\n\\n\", \"Austen's writing career spanned the late 18th and early 19th centuries, a period marked by significant social and economic changes. The Industrial Revolution had created new opportunities for women to enter the workforce, but the constraints of a patriarchal society ensured that their choices and ambitions were often limited. Austen's novels, particularly those featuring strong female protagonists like Elizabeth Bennet in _Pride and Prejudice_ and Elinor Dashwood in _Sense and Sensibility_, proposed a radical alternative to the traditional notion of femininity.\\n\\n\", \"In _Pride and Prejudice_, Austen subverts the conventional notion of a woman's role in society by depicting a heroine who is intelligent, witty, and determined to marry for love rather than convenience. Elizabeth Bennet's opposition to Mr. Collins's proposal, with its implication of a mercenary marriage, is a pointed critique of the social pressures that forced women into unwanted alliances. Austen shows that a woman's happiness and fulfillment depend on her own agency and self-respect, not on the favor of a man.\\n\\n\", \"Similarly, in _Sense and Sensibility_, Austen explores the theme of female independence through the characters of Elinor and Marianne Dashwood. Elinor's cautious and practical approach to love and relationships serves as a foil to Marianne's emotional and expressive nature. While Marianne's enthusiasm and passion are eventually tempered by the demands of reality, Elinor's steady determination to make her own way in life remains a powerful symbol of female autonomy.\\n\\n\", \"Austen's advocacy for female independence was not limited to her novels. In her letters and personal life, she demonstrated a commitment to the values of self-regulation and personal responsibility. A woman of modest means and limited social connections, Austen was aware of the restrictions placed on her by her sex and her station. Yet, she refused to be constrained by these limitations, instead cultivating a spirit of independence and self-reliance that informed her writing and shaped her relationships.\\n\\n\", \"In contrast to the more explosive consequences of the American and French Revolutions, which aimed to overthrow entire systems of power and social order, Austen's quiet revolution was more subtle and insidious. Her novels and letters, written in a tone of gentle persuasion rather than revolutionary fervor, seeped into the social consciousness like a gentle stream, influencing generations of women to come. By depicting strong, independent female characters and advocating for the value of personal autonomy, Austen contributed to a gradual shift in societal attitudes, one that recognized the agency and dignity of women.\\n\\n\", \"Austen's legacy is a testament to the power of quiet, incremental change. Her novels, written during a time of great social upheaval, offer a vision of a more just and equitable society, one in which women are valued for their own worth and agency rather than being defined by their relationships with men. As we reflect on the quiet revolution of Jane Austen's independence, we are reminded that true change often begins with small, subtle shifts in our understanding of the world and our place within it.\\n\\n\", \"In the end, Austen's legacy serves as a reminder that revolution is not always loud or dramatic. Sometimes, the most profound transformations occur through quiet, steady efforts, as individuals and societies work together to create a more just and equitable world. As we celebrate the quiet revolution of Jane Austen's independence, we honor a woman who, through her writing and her life, has inspired generations to stand up for their own freedom and dignity.\"]}\n"
     ]
    }
   ],
   "source": [
    "split_sections = load_dataset(\"nickypro/fineweb-llama3b-regen-split-formatted\", split=\"train\")\n",
    "\n",
    "print(split_sections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e49bd1-a797-4311-8b2d-afc07a9def8c",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Exercise 2: Loading Residual Streams and Embeddings\n",
    "\n",
    " We need to load pre-generated data containing:\n",
    " - Residual stream activations from language models\n",
    " - Corresponding SONAR embeddings of the paragraphs\n",
    " - The actual paragraph text (we got this above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6254f73-e4b1-4bfe-8192-11d7f7989625",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### Part 1: Loading Residual Streams\n",
    " So the transformer model has blocks of:\n",
    " [resid_pre] -> Attention -> [resid_mid] -> MLP -> [resid_post] == [resid_pre_n+1]\n",
    " I have only tested things so far with residual difference\n",
    " I.e: resid_mid = resid_pre + attn_results == resid_pre + resid_mid_diff == resid_pre + (resid_mid - resid_pre)\n",
    " I find it more consistent to calculate (option 1):\n",
    " * resid_mid_diff = resid_mid - resid_pre\n",
    " * resid_post_diff = resid_post - resid_mid\n",
    " alternatively, we could do (option 2):\n",
    " * resid_layer_diff = resid_post - resid_pre\n",
    " which should also work.\n",
    " My testing so far has used option 1, mostly so I can somewhat see where it is easier to extract the information.\n",
    " I suspect that the probes could work also using the basline activations [resid_mid, resid_post] or even just [resid_post], but I haven't tested it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b78d6-55c4-48e4-b39a-71fa5739834d",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " We make hooks for storing activations of the residual stream at the correct positions. That is, the final token of each \"section\" of tokens.\n",
    " For now, we just save [resid_pre, resid_mid, resid_post] at the end of each section.\n",
    " Later we can process it however we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b65e8-8d1e-4117-956f-47a9675ffb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 71]) [torch.Size([1, 15]), torch.Size([1, 105]), torch.Size([1, 111]), torch.Size([1, 107]), torch.Size([1, 92]), torch.Size([1, 95]), torch.Size([1, 113]), torch.Size([1, 102]), torch.Size([1, 88])]\n",
      "['\\n', '**\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.']\n",
      "blocks.0.hook_resid_pre torch.Size([1, 10, 3072])\n"
     ]
    }
   ],
   "source": [
    "def get_act_data(split_text, act_types=None, verbose=False):\n",
    "    # choose which residual data to collect\n",
    "    if act_types is None:\n",
    "        act_types = [\"hook_resid_pre\", \"hook_resid_mid\", \"hook_resid_post\"]\n",
    "    hook_names = [\n",
    "        f\"blocks.{i}.{resid_type}\"\n",
    "            for i in range(model.cfg.n_layers)\n",
    "            for resid_type in act_types\n",
    "    ]\n",
    "\n",
    "    # get prompt vs output separately\n",
    "    prompt = split_text[0]\n",
    "    output = split_text[1:]\n",
    "\n",
    "    # Tokenize the prompt and output correctly\n",
    "    prompt_tokens =  model.to_tokens(prompt, prepend_bos=True)\n",
    "    output_tokens = [model.to_tokens(o, prepend_bos=False) for o in output]\n",
    "    if verbose:\n",
    "        print(prompt_tokens.shape, [o.shape for o in output_tokens])\n",
    "    all_tokens = torch.cat([prompt_tokens, torch.cat(output_tokens, dim=1)], dim=1)\n",
    "\n",
    "    # Get the indices of the residual streams that we want to store\n",
    "    # Ie: last token of each section, usually \"\\n\\n\"\n",
    "    final_indices_rel = [\n",
    "        prompt_tokens.shape[-1],\n",
    "        *[ o.shape[-1] for o in output_tokens ]\n",
    "    ]\n",
    "    final_indices_abs = np.cumsum(final_indices_rel) - 1\n",
    "\n",
    "    # check the tokens are actually the newline ones\n",
    "    if verbose:\n",
    "        print(model.to_str_tokens(all_tokens[:, final_indices_abs]))\n",
    "\n",
    "    # Create hooks to store activations of only the correct residual streams\n",
    "    act_data = {}\n",
    "    def store_act(act, hook):\n",
    "        act_data[hook.name] = act[..., final_indices_abs, :]\n",
    "    hook_list = [(name, store_act) for name in hook_names]\n",
    "\n",
    "    # Run model and store activations\n",
    "    with model.hooks(fwd_hooks=hook_list):\n",
    "        model.forward(all_tokens)\n",
    "\n",
    "    # Print some info\n",
    "    if verbose:\n",
    "        for k, v in act_data.items():\n",
    "            print(k, v.shape)\n",
    "            break\n",
    "\n",
    "    return act_data\n",
    "\n",
    "act_data = get_act_data(split_sections[0][\"split_text\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66d511-f96d-43c0-bc7c-0ec608b54342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 71]) [torch.Size([1, 15]), torch.Size([1, 105]), torch.Size([1, 111]), torch.Size([1, 107]), torch.Size([1, 92]), torch.Size([1, 95]), torch.Size([1, 113]), torch.Size([1, 102]), torch.Size([1, 88])]\n",
      "['\\n', '**\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.\\n\\n', '.']\n",
      "blocks.0.hook_resid_pre torch.Size([1, 10, 3072])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Now we actually save residual stream diff data, as describe as \"option 1\" above.\n",
    "\n",
    "def get_resid_diff_data(split_text, act_types=None, verbose=False):\n",
    "    act_data = get_act_data(split_text, act_types, verbose)\n",
    "\n",
    "    # Calculate the difference between the residual streams\n",
    "    act_data[\"resid_mid_diff\"]  = [\n",
    "        act_data[f\"blocks.{i}.hook_resid_mid\"] - act_data[f\"blocks.{i}.hook_resid_pre\"]\n",
    "        for i in range(model.cfg.n_layers)\n",
    "    ]\n",
    "    act_data[\"resid_post_diff\"] = [\n",
    "        act_data[f\"blocks.{i}.hook_resid_post\"] - act_data[f\"blocks.{i}.hook_resid_mid\"]\n",
    "        for i in range(model.cfg.n_layers)\n",
    "    ]\n",
    "\n",
    "    # Concatenate the data into a single tensor\n",
    "    # I previously did this as [batch==1, layers, tokens, d_model]\n",
    "    # where layers is ordered as [resid_pre_0] + \\\n",
    "    # [mid_diff_0, post_diff_0, mid_diff_1, post_diff_1, ...]\n",
    "    # So for consistency, we store it this way.\n",
    "    full_act_data = [act_data[\"blocks.0.hook_resid_pre\"]]\n",
    "    for i in range(model.cfg.n_layers):\n",
    "        full_act_data.append(act_data[\"resid_mid_diff\"][i])\n",
    "        full_act_data.append(act_data[\"resid_post_diff\"][i])\n",
    "\n",
    "    return torch.cat(full_act_data, dim=0).unsqueeze(0)\n",
    "\n",
    "resid_diff_data = get_resid_diff_data(split_sections[0][\"split_text\"], verbose=True)\n",
    "resid_diff_data.shape\n",
    "\n",
    "# note: I kinda wish I stored things as raw residuals instead of diffs, since it's easier to convert to diffs later.\n",
    "\n",
    "# We are now finished with the model so we can remove it from memory.\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc1282-16fd-4158-874a-41b071d30f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'split': ['<|start_header_id|>user<|end_header_id|>\\nWrite a news feed entry titled \"ACA Repeal Bill Exposed: A Threat to Women\\'s Health\", which includes topics to cover: the potential consequences of the ACA repeal bill on women\\'s health, the opposition from various groups, and the role of the Republican-controlled Congress in shaping the future of healthcare. The entry should be approximately 2-3 paragraphs in length.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n', \"**ACA Repeal Bill Exposed: A Threat to Women's Health**\\n\\n\", \"A recently leaked draft of the proposed American Health Care Act (AHCA) reveals a catastrophic threat to women's health, sparking widespread opposition from healthcare professionals, advocacy groups, and lawmakers alike. The bill, which aims to repeal and replace the Affordable Care Act (ACA), contains provisions that could lead to significant increases in healthcare costs, reduced access to reproductive health services, and increased risk of maternal mortality. Specifically, the bill would eliminate funding for the Preventive Care Women's Rule, which requires insurance plans to cover certain preventive services, including birth control and Pap smears, without cost-sharing. This move would disproportionately affect low-income women, who rely on these services to maintain their health and well-being.\\n\\n\", 'The American College of Obstetricians and Gynecologists (ACOG) and the Planned Parenthood Federation of America (PPFA) have already spoken out against the bill, warning that its repeal would lead to \"disastrous consequences for women\\'s health.\" Other groups, including the National Organization for Women (NOW) and the American Cancer Society, have also voiced their opposition. These organizations argue that the bill\\'s provisions would not only harm women\\'s health but also undermine the economic stability of women, who are the primary breadwinners in many households. As the Republican-controlled Congress prepares to vote on the bill, it remains to be seen whether lawmakers will listen to the warnings of their constituents and the expertise of healthcare professionals.\\n\\n', \"The fate of the ACA repeal bill hangs in the balance, and the impact on women's health is a pressing concern. As lawmakers consider the bill's provisions, they must weigh the interests of the insurance industry and corporate donors against the well-being of the American people. The American people deserve a healthcare system that prioritizes prevention, equality, and access to essential services, not just profit and partisan politics. The outcome of this vote will have far-reaching consequences for the health and well-being of millions of Americans, particularly women.\"], 'indices': [86, 102, 242, 386]}\n",
      "Loaded tensor shape: torch.Size([1, 57, 4, 3072])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Now we load the pre-computed residual stream diffs.\n",
    "\n",
    "\n",
    "# Download and load a specific file (there are total 100 files, 000-099)\n",
    "# Note these are slightly older files, so these match up with a different dataset.\n",
    "\n",
    "split_sections = load_dataset(\"nickypro/llama-3b-split\", split=\"train\")\n",
    "print(split_sections[0])\n",
    "\n",
    "file_path = hf_hub_download(\n",
    "    repo_id=\"nickypro/llama-3b-residuals\",\n",
    "    filename=\"res_data_000.pt\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "# Load the tensor\n",
    "tensor_data = torch.load(file_path)\n",
    "print(f\"Loaded tensor shape: {tensor_data[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c950ae4-68e9-4da7-b09d-e7a00e93afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# ## Creating the embeddings.\n",
    "# Now we use SONAR to create embeddings for each paragraph.\n",
    "# We use the `sonar.inference_pipelines.text.TextToEmbeddingModelPipeline` class to create the embeddings.\n",
    "# We do this for all the paragraphs in the dataset.\n",
    "\n",
    "# Note again we use a slightly older dataset because I haven't uploaded the new ones to huggingface yet.\n",
    "split_sections = load_dataset(\"nickypro/llama-3b-split\", split=\"train\")\n",
    "print(len(split_sections[0]['split']))\n",
    "\n",
    "text2vec = TextToEmbeddingModelPipeline(\n",
    "    encoder=\"text_sonar_basic_encoder\",\n",
    "    tokenizer=\"text_sonar_basic_encoder\",\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE,\n",
    ")\n",
    "\n",
    "vec2text = EmbeddingToTextModelPipeline(\n",
    "    decoder=\"text_sonar_basic_decoder\",\n",
    "    tokenizer=\"text_sonar_basic_encoder\",\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204e4b6-b74f-450c-8ebd-fb21d6157bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:   ['<|start_header_id|>user<|end_header_id|>\\nWrite a news feed entry titled \"ACA Repeal Bill Exposed: A Threat to Women\\'s Health\", which includes topics to cover: the potential consequences of the ACA repeal bill on women\\'s health, the opposition from various groups, and the role of the Republican-controlled Congress in shaping the future of healthcare. The entry should be approximately 2-3 paragraphs in length.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n']\n",
      "predicted:  ['Write a newsfeed entitled \"ACA Repeal Bill Exposed: A Threat to Women\\'s Health\", which contains topics such as: the potential impact of the ACA Repeal Bill on women\\'s health, the opposition from different groups, and the role of the Republican-controlled Congress in shaping the future of health care.']\n",
      "original:   [\"**ACA Repeal Bill Exposed: A Threat to Women's Health**\\n\\n\"]\n",
      "predicted:  [\"**ACA Repeal Bill Exposed: A Threat to Women's Health**\"]\n",
      "original:   [\"A recently leaked draft of the proposed American Health Care Act (AHCA) reveals a catastrophic threat to women's health, sparking widespread opposition from healthcare professionals, advocacy groups, and lawmakers alike. The bill, which aims to repeal and replace the Affordable Care Act (ACA), contains provisions that could lead to significant increases in healthcare costs, reduced access to reproductive health services, and increased risk of maternal mortality. Specifically, the bill would eliminate funding for the Preventive Care Women's Rule, which requires insurance plans to cover certain preventive services, including birth control and Pap smears, without cost-sharing. This move would disproportionately affect low-income women, who rely on these services to maintain their health and well-being.\\n\\n\"]\n",
      "predicted:  [\"A recently unveiled proposed bill by the American Health Care Act (AHCA) poses a devastating threat to women's health, causing widespread opposition from health care professionals, advocates, and lawmakers. The bill, which aims to repeal the Affordable Care Act (ACA), includes provisions that would significantly reduce health care costs, increase access to preventive health care services, and reduce maternal mortality rates. In particular, the bill would require changes to the Affordable Care Act, which would prohibit the provision of prenatal care services, including prescription-only health care, to cover certain expenses.\"]\n",
      "original:   ['The American College of Obstetricians and Gynecologists (ACOG) and the Planned Parenthood Federation of America (PPFA) have already spoken out against the bill, warning that its repeal would lead to \"disastrous consequences for women\\'s health.\" Other groups, including the National Organization for Women (NOW) and the American Cancer Society, have also voiced their opposition. These organizations argue that the bill\\'s provisions would not only harm women\\'s health but also undermine the economic stability of women, who are the primary breadwinners in many households. As the Republican-controlled Congress prepares to vote on the bill, it remains to be seen whether lawmakers will listen to the warnings of their constituents and the expertise of healthcare professionals.\\n\\n']\n",
      "predicted:  ['The American College of Obstetricians and Gynecologists (ACOG) and the Planned Parenthood Federation of America (PPFA) have already spoken out against the bill, warning that its elimination would have adverse effects on \"women\\'s health\". Other groups, including the National Organization for Women (NOW) and the American Cancer Society, have also opposed the proposals. These proposals claim that not only will women\\'s health impair the economic integrity of many women, but that the family will be the first to be taxed in the United States.']\n",
      "original:   [\"The fate of the ACA repeal bill hangs in the balance, and the impact on women's health is a pressing concern. As lawmakers consider the bill's provisions, they must weigh the interests of the insurance industry and corporate donors against the well-being of the American people. The American people deserve a healthcare system that prioritizes prevention, equality, and access to essential services, not just profit and partisan politics. The outcome of this vote will have far-reaching consequences for the health and well-being of millions of Americans, particularly women.\"]\n",
      "predicted:  [\"The fate of the ACA repeal bill is in question, and the impact on women's health is grave. While legislators are considering the implications of the bill, they must weigh the interests of insurance companies and corporate providers against the welfare of the American people. Americans deserve the health care system that gives priority to prevention, equality, and access to essential services, rather than a pro-choice policy. The health outcomes of this will have a profound impact on the health of millions of Americans, particularly women and girls.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% We try to get the embeddings, and also compare some examples of how well it decodes.\n",
    "\n",
    "embeds = []\n",
    "\n",
    "for i, example in enumerate(tqdm(split_sections)):\n",
    "    _id = example[\"id\"]\n",
    "    split_texts = example[\"split\"]\n",
    "    embeddings = text2vec.predict(split_texts, source_lang=\"eng_Latn\")\n",
    "    embeds.append(embeddings)\n",
    "    print(embeddings.shape)\n",
    "    decoded_texts = vec2text.predict(embeddings, target_lang=\"eng_Latn\")\n",
    "    for j, t in enumerate(split_texts):\n",
    "        print(\"original:  \", [t])\n",
    "        print(\"predicted: \", [decoded_texts[j]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe9dff-c4a8-432c-8ec0-ff2170bf47df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024])\n",
      "original:  [\"**ACA Repeal Bill Exposed: A Threat to Women's Health**\\n\\n\"]\n",
      "predicted: [\"**ACA Repeal Bill Exposed: A Threat to Women's Health**\"]\n"
     ]
    }
   ],
   "source": [
    "# %% alternatively, we can yet again use the pre-computed embeddings.\n",
    "\n",
    "embeds = torch.load(hf_hub_download(\n",
    "    repo_id=\"nickypro/llama-3b-embeds\",\n",
    "    filename=\"embeds_000.pt\",\n",
    "    repo_type=\"dataset\"\n",
    "))\n",
    "print(embeds[0].shape)\n",
    "\n",
    "for i, embed in enumerate(embeds):\n",
    "    decoded_texts = vec2text.predict(embed.to(DTYPE), target_lang=\"eng_Latn\")\n",
    "    print(f\"original:  {[split_sections[i]['split'][1]]}\")\n",
    "    print(f\"predicted: {[decoded_texts[0]]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bce2e1-fc3a-4317-97b6-85175ebeb98f",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Now we have shown how to get the data, we can remove the text2vec pipeline from memory. and instead use the pre-computed embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870e3c1-a33c-4b02-a559-9356be21b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "del text2vec\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f2356-9028-4c1f-8a56-56ca395d40ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0\n",
      "torch.Size([4, 57, 3072])\n",
      "torch.Size([4, 1024])\n",
      "['<|start_header_id|>user<|end_header_id|>\\nWrite a news feed entry titled \"ACA Repeal Bill Exposed: A Threat to Women\\'s Health\", which includes topics to cover: the potential consequences of the ACA repeal bill on women\\'s health, the opposition from various groups, and the role of the Republican-controlled Congress in shaping the future of healthcare. The entry should be approximately 2-3 paragraphs in length.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n']\n",
      "[\"**ACA Repeal Bill Exposed: A Threat to Women's Health**\\n\\n\"]\n",
      "[\"A recently leaked draft of the proposed American Health Care Act (AHCA) reveals a catastrophic threat to women's health, sparking widespread opposition from healthcare professionals, advocacy groups, and lawmakers alike. The bill, which aims to repeal and replace the Affordable Care Act (ACA), contains provisions that could lead to significant increases in healthcare costs, reduced access to reproductive health services, and increased risk of maternal mortality. Specifically, the bill would eliminate funding for the Preventive Care Women's Rule, which requires insurance plans to cover certain preventive services, including birth control and Pap smears, without cost-sharing. This move would disproportionately affect low-income women, who rely on these services to maintain their health and well-being.\\n\\n\"]\n",
      "['The American College of Obstetricians and Gynecologists (ACOG) and the Planned Parenthood Federation of America (PPFA) have already spoken out against the bill, warning that its repeal would lead to \"disastrous consequences for women\\'s health.\" Other groups, including the National Organization for Women (NOW) and the American Cancer Society, have also voiced their opposition. These organizations argue that the bill\\'s provisions would not only harm women\\'s health but also undermine the economic stability of women, who are the primary breadwinners in many households. As the Republican-controlled Congress prepares to vote on the bill, it remains to be seen whether lawmakers will listen to the warnings of their constituents and the expertise of healthcare professionals.\\n\\n']\n",
      "[\"The fate of the ACA repeal bill hangs in the balance, and the impact on women's health is a pressing concern. As lawmakers consider the bill's provisions, they must weigh the interests of the insurance industry and corporate donors against the well-being of the American people. The American people deserve a healthcare system that prioritizes prevention, equality, and access to essential services, not just profit and partisan politics. The outcome of this vote will have far-reaching consequences for the health and well-being of millions of Americans, particularly women.\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Now we just load all data.\n",
    "# Note that this data only saves:\n",
    "# - residuals[:-1]\n",
    "# - embeds[1:]\n",
    "# since we only use each residual to predict the next embedding.\n",
    "# Thus they should match up already.\n",
    "\n",
    "def load_all_data(index: int = 0):\n",
    "    split_sections = load_dataset(\"nickypro/llama-3b-split\", split=\"train\")\n",
    "\n",
    "    res_data_file_path = hf_hub_download(\n",
    "        repo_id=\"nickypro/llama-3b-residuals\",\n",
    "        filename=f\"res_data_{index:03d}.pt\",\n",
    "        repo_type=\"dataset\"\n",
    "    )\n",
    "    res_data = torch.load(res_data_file_path, map_location='cpu')\n",
    "\n",
    "    embeds_file_path = hf_hub_download(\n",
    "        repo_id=\"nickypro/llama-3b-embeds\",\n",
    "        filename=f\"embeds_{index:03d}.pt\",\n",
    "        repo_type=\"dataset\"\n",
    "    )\n",
    "    embeds = torch.load(embeds_file_path, map_location='cpu')\n",
    "\n",
    "    assert len(res_data) == len(embeds)\n",
    "    dataset = []\n",
    "    res_reshape = \"1 layer section dim -> section layer dim\"\n",
    "    for i, (res, embed) in enumerate(zip(res_data, embeds)):\n",
    "        _id = i + 1000 * index\n",
    "        dataset.append({\n",
    "            \"id\": _id,\n",
    "            \"res_data\": einops.rearrange(res, res_reshape),\n",
    "            \"embeds\": embed,\n",
    "            \"split_text\": split_sections[_id][\"split\"],\n",
    "        })\n",
    "    return dataset\n",
    "\n",
    "dataset = load_all_data()\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[0][\"id\"])\n",
    "print(dataset[0][\"res_data\"].shape)\n",
    "print(dataset[0][\"embeds\"].shape)\n",
    "[print([p]) for p in dataset[0][\"split_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea75fe6-aeab-4435-9d28-5d064998bca0",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Ok now we have all the data we need. So we can start training, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df970e-1efe-45a6-a9ab-d9c6b568cf25",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Exercise 3: Normalization and Preprocessing\n",
    "\n",
    " One issue with residual streams, is that the magnitudes of the activations can vary a lot between layers, often by orders of magnitude.\n",
    " This can cause issues for training, so we need to normalize the data.\n",
    " We use Welford's algorithm to compute running statistics.\n",
    " We compute the mean and variance of the residual streams and embeddings, and then normalize the data to have mean 0 and variance 1.\n",
    " We then store the mean and variance, so we can restore the data later.\n",
    "\n",
    " In essense, we do the most naive method of normalization, which is to look at each dimension independently and normalize it to have mean 0 and variance 1.\n",
    " There may be better ways do do this, I have not spent much time optimizing this.\n",
    " While we do need to normalize the residuals, I am not sure if we need to do it for the embeddings, but I do it anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e406e6-70aa-4ca3-9e80-01fb35bce999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing normalization statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1124.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized residual mean: 0.0013, std: 1.8984\n",
      "Normalized embeds mean: 0.0130, std: 0.9934\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "@dataclass\n",
    "class WelfordStats:\n",
    "    \"\"\"Track running mean and variance using Welford's algorithm.\"\"\"\n",
    "    mean: torch.Tensor\n",
    "    m2: torch.Tensor\n",
    "    count: int\n",
    "\n",
    "    def __init__(self, mean: torch.Tensor = None, m2: torch.Tensor = None, count: int = 0):\n",
    "        if mean is not None and m2 is not None:\n",
    "            self.mean = mean\n",
    "            self.m2 = m2\n",
    "            self.count = count\n",
    "        else:\n",
    "            self.mean = None\n",
    "            self.m2 = None\n",
    "            self.count = 0\n",
    "\n",
    "    def update(self, new_data: torch.Tensor):\n",
    "        \"\"\"Update statistics with new batch of data (batched version, true Welford).\"\"\"\n",
    "        # new_data: (batch, d)\n",
    "        if self.mean is None or self.m2 is None:\n",
    "            self.mean = torch.zeros_like(new_data[0])\n",
    "            self.m2 = torch.zeros_like(new_data[0])\n",
    "            self.count = 0\n",
    "        for x in new_data:\n",
    "            self.count += 1\n",
    "            delta = x - self.mean\n",
    "            self.mean += delta / self.count\n",
    "            delta2 = x - self.mean\n",
    "            self.m2 += delta * delta2\n",
    "\n",
    "    @property\n",
    "    def sample_variance(self):\n",
    "        # Unbiased sample variance\n",
    "        return self.m2 / (self.count - 1) if self.count > 1 else torch.zeros_like(self.m2)\n",
    "\n",
    "    @property\n",
    "    def population_variance(self):\n",
    "        # Population variance\n",
    "        return self.m2 / self.count if self.count > 0 else torch.zeros_like(self.m2)\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        # Use sample variance by default\n",
    "        return torch.sqrt(self.sample_variance + 1e-6)\n",
    "\n",
    "class Normalizer:\n",
    "    \"\"\"Normalize data using precomputed statistics.\"\"\"\n",
    "    def __init__(self, mean: torch.Tensor, std: torch.Tensor, device: str = DEVICE):\n",
    "        self.mean = mean.to(device)\n",
    "        self.std = std.to(device)\n",
    "\n",
    "    def normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "    def restore(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * (self.std + 1e-6) + self.mean\n",
    "\n",
    "# Compute normalization statistics (in practice, load precomputed stats)\n",
    "print(\"Computing normalization statistics...\")\n",
    "res_stats = WelfordStats()\n",
    "embed_stats = WelfordStats()\n",
    "\n",
    "# Update with data\n",
    "for i, example in enumerate(tqdm(dataset)):\n",
    "    res_stats.update(example[\"res_data\"])\n",
    "    embed_stats.update(example[\"embeds\"])\n",
    "\n",
    "# Create normalizers\n",
    "res_normalizer = Normalizer(res_stats.mean, res_stats.std, device='cpu')\n",
    "embed_normalizer = Normalizer(embed_stats.mean, embed_stats.std, device='cpu')\n",
    "\n",
    "# Test normalization\n",
    "def test_normalization(dataset):\n",
    "    normalized_res    = res_normalizer.normalize(dataset[0][\"res_data\"])\n",
    "    normalized_embeds = embed_normalizer.normalize(dataset[0][\"embeds\"])\n",
    "    print(f\"Normalized residual mean: {normalized_res.mean():.4f}, std: {normalized_res.std():.4f}\")\n",
    "    print(f\"Normalized embeds mean: {normalized_embeds.mean():.4f}, std: {normalized_embeds.std():.4f}\")\n",
    "\n",
    "test_normalization(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616214e3-b45b-4a73-988b-85a38bf732c7",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Exercise 4: Define Probe Models\n",
    "\n",
    " We'll implement a simple Linear probes to map from residual streams to SONAR embeddings.\n",
    " We could take all of the layers [0..57] but I found diminishing returns after 24 layers.\n",
    " I also have tried MLPs, but their performance was basically identical to the linear probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88987364-73f5-4176-a705-8d16ae426b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear probe parameters: 75,498,496\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    \"\"\"Simple linear mapping from residual stream to SONAR embedding.\"\"\"\n",
    "    def __init__(self, d_res: int = 3072, d_sonar: int = 1024, n_layers_to_use: int = 24):\n",
    "        super().__init__()\n",
    "        self.n_layers_to_use = n_layers_to_use\n",
    "        d_in = d_res * self.n_layers_to_use\n",
    "        self.linear = nn.Linear(d_in, d_sonar)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # use the last n_layers_to_use layers of residual diffs\n",
    "        x = x[..., -self.n_layers_to_use:, :].flatten(start_dim=-2)\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create probe models\n",
    "d_res = dataset[0][\"res_data\"].shape[-1]\n",
    "linear_probe = LinearProbe(d_res).to(DEVICE, DTYPE)\n",
    "\n",
    "print(f\"Linear probe parameters: {sum(p.numel() for p in linear_probe.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79fc5f4-a6ec-4ed7-b6c7-5cbe3ce43cfc",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Exercise 5: Training Loop\n",
    "\n",
    " We now train the probe to map from [residual stream] to [SONAR embedding].\n",
    " For efficiency, we currently load data from 10,000 texts (index=0...9), but this could be extended to 100,000 (index=0...99).\n",
    " We use index 99 as a relatively independent validation set, and validate every epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6e294-f6dd-4dea-858a-5a6f2fb8752a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 10 epochs\n",
      "Training files: 10, Validation files: 1\n",
      "Initial LR: 5e-05, LR Decay: 0.8\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:54<00:00, 11.41s/it, Loss=1.2198, LR=5.00e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 1.2198, Val Loss: 1.0859\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:50<00:00, 11.08s/it, Loss=0.9719, LR=4.00e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss: 0.9719, Val Loss: 1.0191\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:37<00:00,  9.75s/it, Loss=0.9096, LR=3.20e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss: 0.9096, Val Loss: 0.9918\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:41<00:00, 16.10s/it, Loss=0.8515, LR=2.56e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss: 0.8515, Val Loss: 0.9723\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:55<00:00, 11.50s/it, Loss=0.8301, LR=2.05e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 0.8301, Val Loss: 0.9617\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:44<00:00, 10.47s/it, Loss=0.8187, LR=1.64e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss: 0.8187, Val Loss: 0.9570\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:46<00:00, 10.65s/it, Loss=0.7958, LR=1.31e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Loss: 0.7958, Val Loss: 0.9520\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it, Loss=0.7925, LR=1.05e-05]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss: 0.7925, Val Loss: 0.9504\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:53<00:00, 11.36s/it, Loss=0.7774, LR=8.39e-06]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss: 0.7774, Val Loss: 0.9473\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:55<00:00, 11.57s/it, Loss=0.7749, LR=6.71e-06]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.7749, Val Loss: 0.9457\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "class ProbeTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        probe: nn.Module,\n",
    "        lr: float = 1e-5,\n",
    "        weight_decay: float = 1e-6,\n",
    "        lr_decay: float = 0.8,\n",
    "        batch_size: int = 1024,\n",
    "        dtype=DTYPE,\n",
    "        device=DEVICE,\n",
    "        checkpoint_dir: str = \"./checkpoints\",\n",
    "    ):\n",
    "        self.probe = probe\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lr_decay = lr_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "\n",
    "        # Training components\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.probe.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            self.optimizer,\n",
    "            step_size=1,\n",
    "            gamma=self.lr_decay\n",
    "        )\n",
    "\n",
    "        # Ensure checkpoint directory exists\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_dataset(dataset: list[dict]):\n",
    "        \"\"\"Convert dataset to tensors and normalize.\"\"\"\n",
    "        dataset_dict = {\n",
    "            \"texts\": [example[\"split_text\"][1:] for example in dataset],\n",
    "            \"res_data\": res_normalizer.normalize(torch.cat([example[\"res_data\"] for example in dataset])),\n",
    "            \"embeds\": embed_normalizer.normalize(torch.cat([example[\"embeds\"] for example in dataset])),\n",
    "        }\n",
    "        return dataset_dict\n",
    "\n",
    "    def get_dataloader(self, res_data, embeds, shuffle=True):\n",
    "        \"\"\"Create DataLoader with proper memory management.\"\"\"\n",
    "        dataset = torch.utils.data.TensorDataset(res_data, embeds)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            pin_memory=True if self.device.type == 'cuda' else False\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def train_epoch(self, epoch: int, train_indices: List[int]) -> float:\n",
    "        \"\"\"Train for one epoch with improved memory management.\"\"\"\n",
    "        self.probe.train()\n",
    "        epoch_train_loss = 0\n",
    "        n_train_batches = 0\n",
    "\n",
    "        pbar = tqdm(train_indices, desc=f\"Train Epoch {epoch+1}\")\n",
    "        for data_idx in pbar:\n",
    "            try:\n",
    "                # Load data for this file\n",
    "                dataset = load_all_data(data_idx)\n",
    "                dataset_dict = self.preprocess_dataset(dataset)\n",
    "                res_data = dataset_dict[\"res_data\"]\n",
    "                embeds = dataset_dict[\"embeds\"].to(self.dtype)\n",
    "\n",
    "                # Create dataloader\n",
    "                loader = self.get_dataloader(res_data, embeds, shuffle=True)\n",
    "\n",
    "                # Training loop for this file\n",
    "                for batch_x, batch_y in loader:\n",
    "                    batch_x = batch_x.to(self.device, non_blocking=True)\n",
    "                    batch_y = batch_y.to(self.device, non_blocking=True)\n",
    "\n",
    "                    # Forward pass\n",
    "                    self.optimizer.zero_grad()\n",
    "                    pred = self.probe(batch_x)\n",
    "                    loss = self.criterion(pred, batch_y)\n",
    "\n",
    "                    # Backward pass\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    epoch_train_loss += loss.item()\n",
    "                    n_train_batches += 1\n",
    "\n",
    "                    # Update progress bar\n",
    "                    current_avg_loss = epoch_train_loss / n_train_batches\n",
    "                    pbar.set_postfix({\n",
    "                        \"Loss\": f\"{current_avg_loss:.4f}\",\n",
    "                        \"LR\": f\"{self.scheduler.get_last_lr()[0]:.2e}\"\n",
    "                    })\n",
    "\n",
    "                # Clean up memory after each file\n",
    "                del dataset, dataset_dict, res_data, embeds, loader\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {data_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "        return epoch_train_loss / max(n_train_batches, 1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, val_indices: List[int]) -> float:\n",
    "        \"\"\"Validate the model with improved memory management.\"\"\"\n",
    "        self.probe.eval()\n",
    "        epoch_val_loss = 0\n",
    "        n_val_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data_idx in tqdm(val_indices, desc=\"Validation\"):\n",
    "                try:\n",
    "                    # Load validation data\n",
    "                    dataset = load_all_data(data_idx)\n",
    "                    dataset_dict = self.preprocess_dataset(dataset)\n",
    "                    res_data = dataset_dict[\"res_data\"]\n",
    "                    embeds = dataset_dict[\"embeds\"].to(self.dtype)\n",
    "\n",
    "                    # Create dataloader\n",
    "                    loader = self.get_dataloader(res_data, embeds, shuffle=False)\n",
    "\n",
    "                    # Validation loop for this file\n",
    "                    for batch_x, batch_y in loader:\n",
    "                        batch_x = batch_x.to(self.device, non_blocking=True)\n",
    "                        batch_y = batch_y.to(self.device, non_blocking=True)\n",
    "\n",
    "                        pred = self.probe(batch_x)\n",
    "                        loss = self.criterion(pred, batch_y)\n",
    "                        epoch_val_loss += loss.item()\n",
    "                        n_val_batches += 1\n",
    "\n",
    "                    # Clean up memory after each file\n",
    "                    del dataset, dataset_dict, res_data, embeds, loader\n",
    "                    gc.collect()\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing validation file {data_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        return epoch_val_loss / max(n_val_batches, 1)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        num_epochs: int = 1,\n",
    "        train_indices: List[int] = list(range(0, 99)),\n",
    "        val_indices: List[int] = [99],\n",
    "        save_checkpoints: bool = False,\n",
    "        validate_every: int = 1,\n",
    "    ) -> Dict[str, List[float]]:\n",
    "        \"\"\"\n",
    "        Main training loop with improved features.\n",
    "\n",
    "        Args:\n",
    "            num_epochs: Number of epochs to train\n",
    "            train_indices: List of data file indices for training\n",
    "            val_indices: List of data file indices for validation\n",
    "            save_checkpoints: Whether to save model checkpoints\n",
    "            validate_every: Validate every N epochs\n",
    "\n",
    "        Returns:\n",
    "            Dictionary containing training and validation losses\n",
    "        \"\"\"\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        print(f\"Starting training for {num_epochs} epochs\")\n",
    "        print(f\"Training files: {len(train_indices)}, Validation files: {len(val_indices)}\")\n",
    "        print(f\"Initial LR: {self.lr}, LR Decay: {self.lr_decay}\")\n",
    "\n",
    "        try:\n",
    "            for epoch in range(num_epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "                # Training\n",
    "                train_loss = self.train_epoch(epoch, train_indices)\n",
    "                train_losses.append(train_loss)\n",
    "\n",
    "                # Validation\n",
    "                if epoch % validate_every == 0 or epoch == num_epochs - 1:\n",
    "                    val_loss = self.validate(val_indices)\n",
    "                    val_losses.append(val_loss)\n",
    "\n",
    "                    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "                    # Save checkpoint\n",
    "                    if save_checkpoints:\n",
    "                        checkpoint_path = os.path.join(\n",
    "                            self.checkpoint_dir,\n",
    "                            f\"probe_epoch_{epoch+1}.pkl\"\n",
    "                        )\n",
    "                        self.save_checkpoint(checkpoint_path, epoch, train_loss, val_loss)\n",
    "                else:\n",
    "                    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "                # Step the learning rate scheduler\n",
    "                self.scheduler.step()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nTraining error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            torch.set_grad_enabled(False)\n",
    "\n",
    "        return {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_path: str, epoch: int, train_loss: float, val_loss: float):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.probe.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path: str):\n",
    "        \"\"\"Load model checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        self.probe.load_state_dict(checkpoint['model_state_dict'])\n",
    "        return checkpoint\n",
    "\n",
    "linear_probe = LinearProbe(d_res).to(DEVICE, DTYPE)\n",
    "\n",
    "# Use the improved ProbeTrainer\n",
    "trainer = ProbeTrainer(\n",
    "    probe=linear_probe,\n",
    "    lr=5e-5,\n",
    "    lr_decay=0.8,\n",
    "    batch_size=1024,\n",
    "    checkpoint_dir=\"./probe_checkpoints\"\n",
    ")\n",
    "\n",
    "# Train with improved features\n",
    "losses = trainer.train(\n",
    "    num_epochs=10,\n",
    "    train_indices=list(range(0, 10)),  # Reduced for demo\n",
    "    val_indices=[99],\n",
    "    save_checkpoints=True,\n",
    "    validate_every=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571206c9-5f5b-4617-b04b-e0f533a90f90",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Test performance of the probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3cdac-e79a-4d95-84d4-0d930e8ba470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec2text already loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    get_name = lambda x: [k for k,v in globals().items() if v is x][0]\n",
    "    print(f\"{get_name(vec2text)} already loaded\")\n",
    "except:\n",
    "    vec2text = EmbeddingToTextModelPipeline(\n",
    "        decoder=\"text_sonar_basic_decoder\",\n",
    "        tokenizer=\"text_sonar_basic_encoder\",\n",
    "        device=DEVICE,\n",
    "        dtype=DTYPE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd9561-b5c8-4e81-a5d0-344b52017f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Mean Squared Error: 0.3125312030315399\n",
      "0: Cosine similarity: 0.5494943857192993\n",
      "0: Original decoded: ** Black Seed Oil: A Comprehensive Review**\n",
      "0: Predicted decoded: **Blank Skin of the Skin: Anatomy a General of the Skin**\n",
      "\n",
      "5: Mean Squared Error: 1.3977200984954834\n",
      "5: Cosine similarity: 0.46341389417648315\n",
      "5: Original decoded: * Calories: 120 * Fat: 14g * Carbohydrates: 0g * Fiber: 0g * Protein: 0g * Vitamin E: 20% of the Daily Value (DV) * Vitamin K: 15% of the DV * Folate: 10% of the DV * Manganese: 10% of the DV\n",
      "5: Predicted decoded: * * Fatty acids * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "\n",
      "10: Mean Squared Error: 0.7131335735321045\n",
      "10: Cosine similarity: 0.4401470720767975\n",
      "10: Original decoded: The health benefits of black seed oil have been extensively studied, and include:\n",
      "10: Predicted decoded: Milk remedies based on black cabbage have been revealed to have numerous anti-inflammatory and anti-inflammatory properties of black cabbage, such as the following:\n",
      "\n",
      "15: Mean Squared Error: 0.17291226983070374\n",
      "15: Cosine similarity: 0.8471386432647705\n",
      "15: Original decoded: **Conclusion **\n",
      "15: Predicted decoded: **Conclusion **\n",
      "\n",
      "20: Mean Squared Error: 1.1124464273452759\n",
      "20: Cosine similarity: 0.41406577825546265\n",
      "20: Original decoded: Sigrid's inspiration for her music comes from a variety of sources, including her own life experiences and observations. Her lyrics often touch on themes of love, identity, and empowerment, focusing on expressing herself and expressing herself as an individual. Her music is a reflection of her journey as a young woman, exploring her birthplace and achievement in the world. With each release, Sigrid continues to push the boundaries of her new sound and style, solidifying herself as one of the most exciting stars in pop music.\n",
      "20: Predicted decoded: She started her music career as a singer, singer, and songwriter in the mid-1980s. She has been influenced by the music of other artists in her life. She has also been influenced by the music of other artists in her lifetime. She has also been influenced by the music of other artists in her life.\n",
      "\n",
      "25: Mean Squared Error: 1.0268669128417969\n",
      "25: Cosine similarity: 0.40714508295059204\n",
      "25: Original decoded: A widespread power outage caused hundreds of thousands of residents in Manhattan on Wednesday night, leaving many without electricity for more than an hour. The outage, which occurred around 6:30 p.m., also disrupted communications, transportation and emergency services in the city.\n",
      "25: Predicted decoded: A massive blackout in New York City that left hundreds of people stranded in the city's power grid and caused widespread blackouts in the city of Phoenix, Arizona, was accompanied by severe power outages.\n",
      "\n",
      "30: Mean Squared Error: 0.7838482856750488\n",
      "30: Cosine similarity: 0.38998180627822876\n",
      "30: Original decoded: As the city begins to recover from the outage, residents feel relieved that the electricity has come back. However, many are wondering when and how the city will finally address its aging infrastructure needs. While the power grid, transportation networks and communication systems are in need of upgrading, the question remains: Should the city take any precautions to prevent such disruptions in the future?\n",
      "30: Predicted decoded: As the crisis continues, the City of New York is pressing ahead with warnings about the potential impact on the energy sector. While the City of New York is struggling to cope with the impact of the crisis, there is a growing need for transparency and accountability.\n",
      "\n",
      "35: Mean Squared Error: 1.1857285499572754\n",
      "35: Cosine similarity: 0.22166618704795837\n",
      "35: Original decoded: The Governor's remarks were echoed by key state stakeholders, including Education Commissioner Catherine Abbatiello, who noted that the initiative is closely aligned with the state's overall economic development strategy.\n",
      "35: Predicted decoded: The support of the nation's high-level decision-makers has also come in support of many other initiatives, such as President Reagan's initiative to increase the number of women in the U.S. public sector and the U.S. House of Representatives in the U.S. House of Representatives and in the U.S. Senate.\n",
      "\n",
      "40: Mean Squared Error: 1.1251311302185059\n",
      "40: Cosine similarity: 0.3054460287094116\n",
      "40: Original decoded: \"We are proud to be part of this effort and to be working with state leaders and other organizations to support the education achievement goal\", said UNC system president Bernadette Byrne. \"We believe education is the key to unleash the full potential of North Carolina's workforce, and we are committed to doing our part to help students succeed\".\n",
      "40: Predicted decoded: \"We are confident of the contribution of higher education to the development of the nation\". \"We are confident of the contribution of higher education to the development of the nation\". \"We are confident of the contribution of higher education to the development of the nation\".\n",
      "\n",
      "45: Mean Squared Error: 1.4002686738967896\n",
      "45: Cosine similarity: 0.2608838379383087\n",
      "45: Original decoded: While you're there, you'll be greeted by the wide selection of beer bottles from Texas, including Lone Star, Live Oak, and Zilker Brewing, but the offer doesn't stop there. Craft Beer also boasts an impressive world-class selection.\n",
      "45: Predicted decoded: Starting with the \"Castle Craft\" grocery store's unique selection of dining spaces, the store thrives on its world-renowned cuisine. In addition to being home to hundreds of specialty bars and salons, the \"Castle Craft\" grocery store features a mind-boggling array of styles ranging from English to Spanish.\n",
      "\n",
      "50: Mean Squared Error: 0.37632521986961365\n",
      "50: Cosine similarity: 0.4161330461502075\n",
      "50: Original decoded: **Insider Tips and Recommendations**\n",
      "50: Predicted decoded: **Guilty Exhibits and Meeting Place**\n",
      "\n",
      "55: Mean Squared Error: 1.1311415433883667\n",
      "55: Cosine similarity: 0.30249929428100586\n",
      "55: Original decoded: **Hours:** Monday  Thursday  15:00  10pm; Friday  Saturday  15:00  11pm; Sunday: 12pm  10pm\n",
      "55: Predicted decoded: **Goal and finishes**\n",
      "\n",
      "60: Mean Squared Error: 1.264923334121704\n",
      "60: Cosine similarity: 0.35754555463790894\n",
      "60: Original decoded: * Retail sales: (713) 526-3645 * Taproom reservations: (713) 526-3645 * Events: (713) 526-3645\n",
      "60: Predicted decoded: * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "\n",
      "65: Mean Squared Error: 1.2717876434326172\n",
      "65: Cosine similarity: 0.25553569197654724\n",
      "65: Original decoded: Methodically, contributors utilize a variety of innovative approaches, including art history analysis, curatorial research, and archival excavation. This multi-faceted methodology allows the authors to retrieve and reinterpret the experiences of lesser-known artists and designers, providing a more nuanced understanding of the Allied Arts movement.\n",
      "65: Predicted decoded: The book's methodology of insight is a meticulous exploration of power and anthropology, the methodology of Bentley's close-mindedness and conversation, facilitating the conceptualization of artistic and social endeavors. The collaborative methodology of Benton's work combines research with cultural and historical perspectives. The methodology of Bentley's work is comprehensive and comprehensive.\n",
      "\n",
      "70: Mean Squared Error: 0.2612834870815277\n",
      "70: Cosine similarity: 0.577965497970581\n",
      "70: Original decoded: ** The CFPB's Regulatory Approach**\n",
      "70: Predicted decoded: **Correction of Payments Regulations**\n",
      "\n",
      "75: Mean Squared Error: 0.4413214921951294\n",
      "75: Cosine similarity: 0.4754991829395294\n",
      "75: Original decoded: **Market Competition **\n",
      "75: Predicted decoded: **Value of the market\n",
      "\n",
      "80: Mean Squared Error: 0.14780496060848236\n",
      "80: Cosine similarity: 0.7940915822982788\n",
      "80: Original decoded: **Conclusion **\n",
      "80: Predicted decoded: **Clearance * **Finish\n",
      "\n",
      "85: Mean Squared Error: 1.2902041673660278\n",
      "85: Cosine similarity: 0.35597991943359375\n",
      "85: Original decoded: This chapter aims to shed light on the meaning of the restored medieval cultural choir in Malta's Mdina Cathedral, and to highlight the historic importance of late Gothic art in the cultural landscape of the island. By examining the historical context, artistic innovations and cultural impact of this period, we will unveil the forgotten medieval era of Malta and demonstrate its lasting influence on the identity of the island.\n",
      "85: Predicted decoded: The history of the MedellÃ­n Fortress in the Netherlands is a fascinating reflection of the medieval architecture of the city of Vienna, which stood at the heart of the renowned Medieval traditions of the fortress, this monumental work of art by the Crusaders of the Middle Ages was inspired by and reflects the unique architectural style of the city of Vienna. At the beginning of the 19th century, the museum exhibited valuable artifacts of MedellÃ­n, which served as an inspiration for the historical and cultural legacy of the city.\n",
      "\n",
      "90: Mean Squared Error: 0.43976616859436035\n",
      "90: Cosine similarity: 0.4608531594276428\n",
      "90: Original decoded: **The Art Historical Importance of the Late Gothic era**\n",
      "90: Predicted decoded: **Artistic Schools of Art and Design**\n",
      "\n",
      "95: Mean Squared Error: 0.9776298403739929\n",
      "95: Cosine similarity: 0.38405463099479675\n",
      "95: Original decoded: The Cathedral Chapter and Universitas played a crucial role in shaping Malta's cultural landscape during the medieval period. The Chapter, which was responsible for the governance and administration of the cathedral, was composed of high-ranking clergy and nobles who were responsible for the spiritual and temporal welfare of the community.\n",
      "95: Predicted decoded: The MedellÃ­n Cathedral is an integral part of the Church of Denmark's re-establishment. The university is a symbol of Gothic tradition. The university, which played a pivotal role in the revival of Gothic architecture in the 17th and 18th centuries, was founded in the mid-17th century by the architects of the city.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "dataset_dict = ProbeTrainer.preprocess_dataset(load_all_data(99))\n",
    "\n",
    "for i, (text, res, emb) in list(enumerate(zip(dataset_dict[\"texts\"], dataset_dict[\"res_data\"], dataset_dict[\"embeds\"])))[:100:5]:\n",
    "    output = linear_probe(res.to(DEVICE)).to('cpu')\n",
    "    emb    = emb.to('cpu')\n",
    "    print(f\"{i}: Mean Squared Error: {torch.nn.functional.mse_loss(emb, output)}\")\n",
    "    print(f\"{i}: Cosine similarity: {torch.nn.functional.cosine_similarity(emb, output, dim=0)}\")\n",
    "    output = embed_normalizer.restore(output).to(DEVICE, DTYPE)\n",
    "    emb    = embed_normalizer.restore(emb).to(DEVICE, DTYPE)\n",
    "    predictions = vec2text.predict([emb, output], target_lang=\"eng_Latn\")\n",
    "    print(f\"{i}: Original decoded: {predictions[0]}\")\n",
    "    print(f\"{i}: Predicted decoded: {predictions[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d2bfd-af19-469a-92b0-b45777c79afa",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " You should see that some predictions are pretty similar to the original text.\n",
    " And some of them are completelly broken tbh.\n",
    " You can get better results if you increase train_indices to be range(0, 99), but this will take a while."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
